{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmented EDA customers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boscoybarra/customer-transaction-prediction/blob/master/Augmented_EDA_customers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fp-SoCi5UNAt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ]
    },
    {
      "metadata": {
        "id": "_ICfeeyfUHy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dx6idQtVUhYl",
        "colab_type": "code",
        "outputId": "4546e124-c263-490f-fe8d-43f79d292d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# Gradient Boosting\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Graphics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Skopt functions\n",
        "!pip install scikit-optimize\n",
        "from skopt import gp_minimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt import gp_minimize # Bayesian optimization using Gaussian Processes\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.utils import use_named_args # decorator to convert a list of parameters to named arguments\n",
        "from skopt.callbacks import DeadlineStopper # Stop the optimization before running out of a fixed budget of time.\n",
        "from skopt.callbacks import VerboseCallback # Callback to control the verbosity\n",
        "from skopt.callbacks import DeltaXStopper # Stop the optimization If the last two positions at which the objective has been evaluated are less than delta\n",
        "\n",
        "# Hyperparameters distributions\n",
        "from scipy.stats import randint\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, mean_absolute_error\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "def ignore_warn(*args, **kwargs):\n",
        "    pass\n",
        "warnings.warn = ignore_warn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.20.3)\n",
            "Installing collected packages: scikit-optimize\n",
            "Successfully installed scikit-optimize-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zF7RDCcVUoWH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "santander_data = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/train.csv')\n",
        "santander_data_test = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrUZDlsZUQvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_df = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/train.csv')\n",
        "# test_df = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/test.csv')\n",
        "# sample_submission = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Onc7llIcGMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Taking the labels (price)\n",
        "label_df = santander_data['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RG2Hass_cGhX",
        "colab_type": "code",
        "outputId": "6e8af523-4a11-433b-d760-b38f338806a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "santander_data.drop(['ID_code','target'], axis=1, inplace=True)\n",
        "\n",
        "santander_data_test.drop('ID_code', axis=1, inplace=True)\n",
        "santander_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>-4.9200</td>\n",
              "      <td>5.7470</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>3.1468</td>\n",
              "      <td>8.0851</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>-4.9193</td>\n",
              "      <td>5.9525</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>-5.8609</td>\n",
              "      <td>8.2450</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>7.6784</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11.4763</td>\n",
              "      <td>-2.3182</td>\n",
              "      <td>12.6080</td>\n",
              "      <td>8.6264</td>\n",
              "      <td>10.9621</td>\n",
              "      <td>3.5609</td>\n",
              "      <td>4.5322</td>\n",
              "      <td>15.2255</td>\n",
              "      <td>3.5855</td>\n",
              "      <td>5.9790</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.3068</td>\n",
              "      <td>6.6025</td>\n",
              "      <td>5.2912</td>\n",
              "      <td>0.4403</td>\n",
              "      <td>14.9452</td>\n",
              "      <td>1.0314</td>\n",
              "      <td>-3.6241</td>\n",
              "      <td>9.7670</td>\n",
              "      <td>12.5809</td>\n",
              "      <td>-4.7602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11.8091</td>\n",
              "      <td>-0.0832</td>\n",
              "      <td>9.3494</td>\n",
              "      <td>4.2916</td>\n",
              "      <td>11.1355</td>\n",
              "      <td>-8.0198</td>\n",
              "      <td>6.1961</td>\n",
              "      <td>12.0771</td>\n",
              "      <td>-4.3781</td>\n",
              "      <td>7.9232</td>\n",
              "      <td>...</td>\n",
              "      <td>8.7830</td>\n",
              "      <td>6.4521</td>\n",
              "      <td>3.5325</td>\n",
              "      <td>0.1777</td>\n",
              "      <td>18.3314</td>\n",
              "      <td>0.5845</td>\n",
              "      <td>9.1104</td>\n",
              "      <td>9.1143</td>\n",
              "      <td>10.8869</td>\n",
              "      <td>-3.2097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.5580</td>\n",
              "      <td>-7.9881</td>\n",
              "      <td>13.8776</td>\n",
              "      <td>7.5985</td>\n",
              "      <td>8.6543</td>\n",
              "      <td>0.8310</td>\n",
              "      <td>5.6890</td>\n",
              "      <td>22.3262</td>\n",
              "      <td>5.0647</td>\n",
              "      <td>7.1971</td>\n",
              "      <td>...</td>\n",
              "      <td>13.1700</td>\n",
              "      <td>6.5491</td>\n",
              "      <td>3.9906</td>\n",
              "      <td>5.8061</td>\n",
              "      <td>23.1407</td>\n",
              "      <td>-0.3776</td>\n",
              "      <td>4.2178</td>\n",
              "      <td>9.4237</td>\n",
              "      <td>8.6624</td>\n",
              "      <td>3.4806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16.1071</td>\n",
              "      <td>2.4426</td>\n",
              "      <td>13.9307</td>\n",
              "      <td>5.6327</td>\n",
              "      <td>8.8014</td>\n",
              "      <td>6.1630</td>\n",
              "      <td>4.4514</td>\n",
              "      <td>10.1854</td>\n",
              "      <td>-3.1882</td>\n",
              "      <td>9.0827</td>\n",
              "      <td>...</td>\n",
              "      <td>1.4298</td>\n",
              "      <td>14.7510</td>\n",
              "      <td>1.6395</td>\n",
              "      <td>1.4181</td>\n",
              "      <td>14.8370</td>\n",
              "      <td>-1.9940</td>\n",
              "      <td>-1.0733</td>\n",
              "      <td>8.1975</td>\n",
              "      <td>19.5114</td>\n",
              "      <td>4.8453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.5088</td>\n",
              "      <td>1.9743</td>\n",
              "      <td>8.8960</td>\n",
              "      <td>5.4508</td>\n",
              "      <td>13.6043</td>\n",
              "      <td>-16.2859</td>\n",
              "      <td>6.0637</td>\n",
              "      <td>16.8410</td>\n",
              "      <td>0.1287</td>\n",
              "      <td>7.9682</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5543</td>\n",
              "      <td>6.3160</td>\n",
              "      <td>1.0371</td>\n",
              "      <td>3.6885</td>\n",
              "      <td>14.8344</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>14.1287</td>\n",
              "      <td>7.9133</td>\n",
              "      <td>16.2375</td>\n",
              "      <td>14.2514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
              "0   8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187  18.6266   \n",
              "1  11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208  16.5338   \n",
              "2   8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427  14.6155   \n",
              "3  11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428  14.9250   \n",
              "4   9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405  19.2514   \n",
              "5  11.4763 -2.3182  12.6080  8.6264  10.9621   3.5609  4.5322  15.2255   \n",
              "6  11.8091 -0.0832   9.3494  4.2916  11.1355  -8.0198  6.1961  12.0771   \n",
              "7  13.5580 -7.9881  13.8776  7.5985   8.6543   0.8310  5.6890  22.3262   \n",
              "8  16.1071  2.4426  13.9307  5.6327   8.8014   6.1630  4.4514  10.1854   \n",
              "9  12.5088  1.9743   8.8960  5.4508  13.6043 -16.2859  6.0637  16.8410   \n",
              "\n",
              "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
              "0 -4.9200  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
              "1  3.1468  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
              "2 -4.9193  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
              "3 -5.8609  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
              "4  6.2654  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
              "5  3.5855  5.9790   ...     -6.3068   6.6025   5.2912   0.4403  14.9452   \n",
              "6 -4.3781  7.9232   ...      8.7830   6.4521   3.5325   0.1777  18.3314   \n",
              "7  5.0647  7.1971   ...     13.1700   6.5491   3.9906   5.8061  23.1407   \n",
              "8 -3.1882  9.0827   ...      1.4298  14.7510   1.6395   1.4181  14.8370   \n",
              "9  0.1287  7.9682   ...      0.5543   6.3160   1.0371   3.6885  14.8344   \n",
              "\n",
              "   var_195  var_196  var_197  var_198  var_199  \n",
              "0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
              "2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
              "5   1.0314  -3.6241   9.7670  12.5809  -4.7602  \n",
              "6   0.5845   9.1104   9.1143  10.8869  -3.2097  \n",
              "7  -0.3776   4.2178   9.4237   8.6624   3.4806  \n",
              "8  -1.9940  -1.0733   8.1975  19.5114   4.8453  \n",
              "9   0.4467  14.1287   7.9133  16.2375  14.2514  \n",
              "\n",
              "[10 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "2_CHVXg5cIbH",
        "colab_type": "code",
        "outputId": "e654aadb-6434-479e-e87e-148b2ac011c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "santander_data_test.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0656</td>\n",
              "      <td>7.7798</td>\n",
              "      <td>12.9536</td>\n",
              "      <td>9.4292</td>\n",
              "      <td>11.4327</td>\n",
              "      <td>-2.3805</td>\n",
              "      <td>5.8493</td>\n",
              "      <td>18.2675</td>\n",
              "      <td>2.1337</td>\n",
              "      <td>8.8100</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1556</td>\n",
              "      <td>11.8495</td>\n",
              "      <td>-1.4300</td>\n",
              "      <td>2.4508</td>\n",
              "      <td>13.7112</td>\n",
              "      <td>2.4669</td>\n",
              "      <td>4.3654</td>\n",
              "      <td>10.7200</td>\n",
              "      <td>15.4722</td>\n",
              "      <td>-8.7197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.5304</td>\n",
              "      <td>1.2543</td>\n",
              "      <td>11.3047</td>\n",
              "      <td>5.1858</td>\n",
              "      <td>9.1974</td>\n",
              "      <td>-4.0117</td>\n",
              "      <td>6.0196</td>\n",
              "      <td>18.6316</td>\n",
              "      <td>-4.4131</td>\n",
              "      <td>5.9739</td>\n",
              "      <td>...</td>\n",
              "      <td>10.6165</td>\n",
              "      <td>8.8349</td>\n",
              "      <td>0.9403</td>\n",
              "      <td>10.1282</td>\n",
              "      <td>15.5765</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>-1.4852</td>\n",
              "      <td>9.8714</td>\n",
              "      <td>19.1293</td>\n",
              "      <td>-20.9760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.4827</td>\n",
              "      <td>-10.3581</td>\n",
              "      <td>10.1407</td>\n",
              "      <td>7.0479</td>\n",
              "      <td>10.2628</td>\n",
              "      <td>9.8052</td>\n",
              "      <td>4.8950</td>\n",
              "      <td>20.2537</td>\n",
              "      <td>1.5233</td>\n",
              "      <td>8.3442</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7484</td>\n",
              "      <td>10.9935</td>\n",
              "      <td>1.9803</td>\n",
              "      <td>2.1800</td>\n",
              "      <td>12.9813</td>\n",
              "      <td>2.1281</td>\n",
              "      <td>-7.1086</td>\n",
              "      <td>7.0618</td>\n",
              "      <td>19.8956</td>\n",
              "      <td>-23.1794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5374</td>\n",
              "      <td>-1.3222</td>\n",
              "      <td>12.0220</td>\n",
              "      <td>6.5749</td>\n",
              "      <td>8.8458</td>\n",
              "      <td>3.1744</td>\n",
              "      <td>4.9397</td>\n",
              "      <td>20.5660</td>\n",
              "      <td>3.3755</td>\n",
              "      <td>7.4578</td>\n",
              "      <td>...</td>\n",
              "      <td>9.5702</td>\n",
              "      <td>9.0766</td>\n",
              "      <td>1.6580</td>\n",
              "      <td>3.5813</td>\n",
              "      <td>15.1874</td>\n",
              "      <td>3.1656</td>\n",
              "      <td>3.9567</td>\n",
              "      <td>9.2295</td>\n",
              "      <td>13.0168</td>\n",
              "      <td>-4.2108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.7058</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>14.1295</td>\n",
              "      <td>7.7506</td>\n",
              "      <td>9.1035</td>\n",
              "      <td>-8.5848</td>\n",
              "      <td>6.8595</td>\n",
              "      <td>10.6048</td>\n",
              "      <td>2.9890</td>\n",
              "      <td>7.1437</td>\n",
              "      <td>...</td>\n",
              "      <td>4.2259</td>\n",
              "      <td>9.1723</td>\n",
              "      <td>1.2835</td>\n",
              "      <td>3.3778</td>\n",
              "      <td>19.5542</td>\n",
              "      <td>-0.2860</td>\n",
              "      <td>-5.1612</td>\n",
              "      <td>7.2882</td>\n",
              "      <td>13.9260</td>\n",
              "      <td>-9.1846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.9862</td>\n",
              "      <td>-2.2913</td>\n",
              "      <td>8.6058</td>\n",
              "      <td>7.0685</td>\n",
              "      <td>14.2465</td>\n",
              "      <td>-8.6761</td>\n",
              "      <td>4.2467</td>\n",
              "      <td>14.7632</td>\n",
              "      <td>1.8790</td>\n",
              "      <td>7.2842</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1115</td>\n",
              "      <td>7.1178</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>8.8781</td>\n",
              "      <td>14.9438</td>\n",
              "      <td>-2.2151</td>\n",
              "      <td>-6.0233</td>\n",
              "      <td>9.8117</td>\n",
              "      <td>17.1127</td>\n",
              "      <td>10.8240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.4624</td>\n",
              "      <td>-6.1065</td>\n",
              "      <td>7.3603</td>\n",
              "      <td>8.2627</td>\n",
              "      <td>12.0104</td>\n",
              "      <td>-7.2073</td>\n",
              "      <td>4.1670</td>\n",
              "      <td>13.0809</td>\n",
              "      <td>-4.3004</td>\n",
              "      <td>6.3181</td>\n",
              "      <td>...</td>\n",
              "      <td>12.3609</td>\n",
              "      <td>6.8661</td>\n",
              "      <td>4.0971</td>\n",
              "      <td>8.8484</td>\n",
              "      <td>17.5010</td>\n",
              "      <td>0.0295</td>\n",
              "      <td>7.7443</td>\n",
              "      <td>9.1509</td>\n",
              "      <td>18.4736</td>\n",
              "      <td>5.1499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17.3035</td>\n",
              "      <td>-2.4212</td>\n",
              "      <td>13.3989</td>\n",
              "      <td>8.3998</td>\n",
              "      <td>11.0777</td>\n",
              "      <td>9.6449</td>\n",
              "      <td>5.9596</td>\n",
              "      <td>17.8477</td>\n",
              "      <td>-4.8068</td>\n",
              "      <td>7.4643</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4676</td>\n",
              "      <td>4.4214</td>\n",
              "      <td>0.9303</td>\n",
              "      <td>1.4994</td>\n",
              "      <td>15.2648</td>\n",
              "      <td>-1.7931</td>\n",
              "      <td>6.5316</td>\n",
              "      <td>10.4855</td>\n",
              "      <td>23.4631</td>\n",
              "      <td>0.7283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.9856</td>\n",
              "      <td>0.8402</td>\n",
              "      <td>13.7161</td>\n",
              "      <td>4.7749</td>\n",
              "      <td>8.6784</td>\n",
              "      <td>-13.7607</td>\n",
              "      <td>4.3386</td>\n",
              "      <td>14.5843</td>\n",
              "      <td>2.5883</td>\n",
              "      <td>7.2215</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.4657</td>\n",
              "      <td>7.8754</td>\n",
              "      <td>2.4698</td>\n",
              "      <td>-0.0362</td>\n",
              "      <td>16.7144</td>\n",
              "      <td>0.1221</td>\n",
              "      <td>-1.4328</td>\n",
              "      <td>9.9207</td>\n",
              "      <td>16.9865</td>\n",
              "      <td>-3.3304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.3811</td>\n",
              "      <td>-6.9348</td>\n",
              "      <td>14.6690</td>\n",
              "      <td>9.0941</td>\n",
              "      <td>11.9058</td>\n",
              "      <td>-10.8018</td>\n",
              "      <td>3.4508</td>\n",
              "      <td>20.2816</td>\n",
              "      <td>-1.4112</td>\n",
              "      <td>6.7401</td>\n",
              "      <td>...</td>\n",
              "      <td>1.8052</td>\n",
              "      <td>11.0723</td>\n",
              "      <td>0.8907</td>\n",
              "      <td>4.7680</td>\n",
              "      <td>15.1425</td>\n",
              "      <td>0.6075</td>\n",
              "      <td>-4.4447</td>\n",
              "      <td>9.5788</td>\n",
              "      <td>15.8146</td>\n",
              "      <td>9.3457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0    var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
              "0  11.0656   7.7798  12.9536  9.4292  11.4327  -2.3805  5.8493  18.2675   \n",
              "1   8.5304   1.2543  11.3047  5.1858   9.1974  -4.0117  6.0196  18.6316   \n",
              "2   5.4827 -10.3581  10.1407  7.0479  10.2628   9.8052  4.8950  20.2537   \n",
              "3   8.5374  -1.3222  12.0220  6.5749   8.8458   3.1744  4.9397  20.5660   \n",
              "4  11.7058  -0.1327  14.1295  7.7506   9.1035  -8.5848  6.8595  10.6048   \n",
              "5   5.9862  -2.2913   8.6058  7.0685  14.2465  -8.6761  4.2467  14.7632   \n",
              "6   8.4624  -6.1065   7.3603  8.2627  12.0104  -7.2073  4.1670  13.0809   \n",
              "7  17.3035  -2.4212  13.3989  8.3998  11.0777   9.6449  5.9596  17.8477   \n",
              "8   6.9856   0.8402  13.7161  4.7749   8.6784 -13.7607  4.3386  14.5843   \n",
              "9  10.3811  -6.9348  14.6690  9.0941  11.9058 -10.8018  3.4508  20.2816   \n",
              "\n",
              "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
              "0  2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
              "1 -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
              "2  1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
              "3  3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
              "4  2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
              "5  1.8790  7.2842   ...     -2.1115   7.1178  -0.4249   8.8781  14.9438   \n",
              "6 -4.3004  6.3181   ...     12.3609   6.8661   4.0971   8.8484  17.5010   \n",
              "7 -4.8068  7.4643   ...      4.4676   4.4214   0.9303   1.4994  15.2648   \n",
              "8  2.5883  7.2215   ...     -3.4657   7.8754   2.4698  -0.0362  16.7144   \n",
              "9 -1.4112  6.7401   ...      1.8052  11.0723   0.8907   4.7680  15.1425   \n",
              "\n",
              "   var_195  var_196  var_197  var_198  var_199  \n",
              "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
              "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
              "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
              "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
              "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
              "5  -2.2151  -6.0233   9.8117  17.1127  10.8240  \n",
              "6   0.0295   7.7443   9.1509  18.4736   5.1499  \n",
              "7  -1.7931   6.5316  10.4855  23.4631   0.7283  \n",
              "8   0.1221  -1.4328   9.9207  16.9865  -3.3304  \n",
              "9   0.6075  -4.4447   9.5788  15.8146   9.3457  \n",
              "\n",
              "[10 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "3qho8hKfcKg_",
        "colab_type": "code",
        "outputId": "1470f9e5-604e-4c90-b4eb-77e3ac4ddb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "santander_data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.679914</td>\n",
              "      <td>-1.627622</td>\n",
              "      <td>10.715192</td>\n",
              "      <td>6.796529</td>\n",
              "      <td>11.078333</td>\n",
              "      <td>-5.065317</td>\n",
              "      <td>5.408949</td>\n",
              "      <td>16.545850</td>\n",
              "      <td>0.284162</td>\n",
              "      <td>7.567236</td>\n",
              "      <td>...</td>\n",
              "      <td>3.234440</td>\n",
              "      <td>7.438408</td>\n",
              "      <td>1.927839</td>\n",
              "      <td>3.331774</td>\n",
              "      <td>17.993784</td>\n",
              "      <td>-0.142088</td>\n",
              "      <td>2.303335</td>\n",
              "      <td>8.908158</td>\n",
              "      <td>15.870720</td>\n",
              "      <td>-3.326537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.040051</td>\n",
              "      <td>4.050044</td>\n",
              "      <td>2.640894</td>\n",
              "      <td>2.043319</td>\n",
              "      <td>1.623150</td>\n",
              "      <td>7.863267</td>\n",
              "      <td>0.866607</td>\n",
              "      <td>3.418076</td>\n",
              "      <td>3.332634</td>\n",
              "      <td>1.235070</td>\n",
              "      <td>...</td>\n",
              "      <td>4.559922</td>\n",
              "      <td>3.023272</td>\n",
              "      <td>1.478423</td>\n",
              "      <td>3.992030</td>\n",
              "      <td>3.135162</td>\n",
              "      <td>1.429372</td>\n",
              "      <td>5.454369</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>3.010945</td>\n",
              "      <td>10.438015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>3.970500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.453850</td>\n",
              "      <td>-4.740025</td>\n",
              "      <td>8.722475</td>\n",
              "      <td>5.254075</td>\n",
              "      <td>9.883175</td>\n",
              "      <td>-11.200350</td>\n",
              "      <td>4.767700</td>\n",
              "      <td>13.943800</td>\n",
              "      <td>-2.317800</td>\n",
              "      <td>6.618800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>5.157400</td>\n",
              "      <td>0.889775</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>15.629800</td>\n",
              "      <td>-1.170700</td>\n",
              "      <td>-1.946925</td>\n",
              "      <td>8.252800</td>\n",
              "      <td>13.829700</td>\n",
              "      <td>-11.208475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.524750</td>\n",
              "      <td>-1.608050</td>\n",
              "      <td>10.580000</td>\n",
              "      <td>6.825000</td>\n",
              "      <td>11.108250</td>\n",
              "      <td>-4.833150</td>\n",
              "      <td>5.385100</td>\n",
              "      <td>16.456800</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>7.629600</td>\n",
              "      <td>...</td>\n",
              "      <td>3.203600</td>\n",
              "      <td>7.347750</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>3.396350</td>\n",
              "      <td>17.957950</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>2.408900</td>\n",
              "      <td>8.888200</td>\n",
              "      <td>15.934050</td>\n",
              "      <td>-2.819550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.758200</td>\n",
              "      <td>1.358625</td>\n",
              "      <td>12.516700</td>\n",
              "      <td>8.324100</td>\n",
              "      <td>12.261125</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.102900</td>\n",
              "      <td>2.937900</td>\n",
              "      <td>8.584425</td>\n",
              "      <td>...</td>\n",
              "      <td>6.406200</td>\n",
              "      <td>9.512525</td>\n",
              "      <td>2.949500</td>\n",
              "      <td>6.205800</td>\n",
              "      <td>20.396525</td>\n",
              "      <td>0.829600</td>\n",
              "      <td>6.556725</td>\n",
              "      <td>9.593300</td>\n",
              "      <td>18.064725</td>\n",
              "      <td>4.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>11.150600</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               var_0          var_1          var_2          var_3  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       10.679914      -1.627622      10.715192       6.796529   \n",
              "std         3.040051       4.050044       2.640894       2.043319   \n",
              "min         0.408400     -15.043400       2.117100      -0.040200   \n",
              "25%         8.453850      -4.740025       8.722475       5.254075   \n",
              "50%        10.524750      -1.608050      10.580000       6.825000   \n",
              "75%        12.758200       1.358625      12.516700       8.324100   \n",
              "max        20.315000      10.376800      19.353000      13.188300   \n",
              "\n",
              "               var_4          var_5          var_6          var_7  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       11.078333      -5.065317       5.408949      16.545850   \n",
              "std         1.623150       7.863267       0.866607       3.418076   \n",
              "min         5.074800     -32.562600       2.347300       5.349700   \n",
              "25%         9.883175     -11.200350       4.767700      13.943800   \n",
              "50%        11.108250      -4.833150       5.385100      16.456800   \n",
              "75%        12.261125       0.924800       6.003000      19.102900   \n",
              "max        16.671400      17.251600       8.447700      27.691800   \n",
              "\n",
              "               var_8          var_9      ...              var_190  \\\n",
              "count  200000.000000  200000.000000      ...        200000.000000   \n",
              "mean        0.284162       7.567236      ...             3.234440   \n",
              "std         3.332634       1.235070      ...             4.559922   \n",
              "min       -10.505500       3.970500      ...           -14.093300   \n",
              "25%        -2.317800       6.618800      ...            -0.058825   \n",
              "50%         0.393700       7.629600      ...             3.203600   \n",
              "75%         2.937900       8.584425      ...             6.406200   \n",
              "max        10.151300      11.150600      ...            18.440900   \n",
              "\n",
              "             var_191        var_192        var_193        var_194  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        7.438408       1.927839       3.331774      17.993784   \n",
              "std         3.023272       1.478423       3.992030       3.135162   \n",
              "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
              "25%         5.157400       0.889775       0.584600      15.629800   \n",
              "50%         7.347750       1.901300       3.396350      17.957950   \n",
              "75%         9.512525       2.949500       6.205800      20.396525   \n",
              "max        16.716500       8.402400      18.281800      27.928800   \n",
              "\n",
              "             var_195        var_196        var_197        var_198  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       -0.142088       2.303335       8.908158      15.870720   \n",
              "std         1.429372       5.454369       0.921625       3.010945   \n",
              "min        -5.261000     -14.209600       5.960600       6.299300   \n",
              "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
              "50%        -0.172700       2.408900       8.888200      15.934050   \n",
              "75%         0.829600       6.556725       9.593300      18.064725   \n",
              "max         4.272900      18.321500      12.000400      26.079100   \n",
              "\n",
              "             var_199  \n",
              "count  200000.000000  \n",
              "mean       -3.326537  \n",
              "std        10.438015  \n",
              "min       -38.852800  \n",
              "25%       -11.208475  \n",
              "50%        -2.819550  \n",
              "75%         4.836800  \n",
              "max        28.500700  \n",
              "\n",
              "[8 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "V6-j6rAPcMfv",
        "colab_type": "code",
        "outputId": "ed8641ce-06aa-42e7-97b2-0aa67e4847dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "santander_data[santander_data.isnull().any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9, var_10, var_11, var_12, var_13, var_14, var_15, var_16, var_17, var_18, var_19, var_20, var_21, var_22, var_23, var_24, var_25, var_26, var_27, var_28, var_29, var_30, var_31, var_32, var_33, var_34, var_35, var_36, var_37, var_38, var_39, var_40, var_41, var_42, var_43, var_44, var_45, var_46, var_47, var_48, var_49, var_50, var_51, var_52, var_53, var_54, var_55, var_56, var_57, var_58, var_59, var_60, var_61, var_62, var_63, var_64, var_65, var_66, var_67, var_68, var_69, var_70, var_71, var_72, var_73, var_74, var_75, var_76, var_77, var_78, var_79, var_80, var_81, var_82, var_83, var_84, var_85, var_86, var_87, var_88, var_89, var_90, var_91, var_92, var_93, var_94, var_95, var_96, var_97, var_98, var_99, ...]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "OLZBBfk3cXK2",
        "colab_type": "code",
        "outputId": "9f398ac6-179a-4a21-e538-abe58decbe2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "santander_data.select_dtypes(exclude=np.number).columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "1FtqST4LcaId",
        "colab_type": "code",
        "outputId": "225def4f-6b35-4a88-f50e-094a5884fa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "len_train = len(santander_data)\n",
        "len_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "9ntCj3sTceHf",
        "colab_type": "code",
        "outputId": "6b73dda1-2015-4be4-e717-886d031fb88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "#Merge test and train\n",
        "merged = pd.concat([santander_data, santander_data_test])\n",
        "#Saving the list of original features in a new list `original_features`.\n",
        "original_features = merged.columns\n",
        "merged.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "UZRxl7FhchuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = features = merged.columns.values[0:200]\n",
        "for df in [merged]:\n",
        "    df['sum'] = df[idx].sum(axis=1)  \n",
        "    df['min'] = df[idx].min(axis=1)\n",
        "    df['max'] = df[idx].max(axis=1)\n",
        "    df['mean'] = df[idx].mean(axis=1)\n",
        "    df['std'] = df[idx].std(axis=1)\n",
        "    df['skew'] = df[idx].skew(axis=1)\n",
        "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
        "    df['med'] = df[idx].median(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwU_H1fIcmKD",
        "colab_type": "code",
        "outputId": "f8088128-e9a0-4009-db29-ca06e8b9b3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of features: \",merged.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of features:  208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MispPB9_cp1j",
        "colab_type": "code",
        "outputId": "b9152edc-49e1-4922-ccaf-a1e592d23792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "train_df = merged.iloc[:len_train]\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "      <th>sum</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurt</th>\n",
              "      <th>med</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>-4.9200</td>\n",
              "      <td>5.7470</td>\n",
              "      <td>...</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "      <td>1456.3182</td>\n",
              "      <td>-21.4494</td>\n",
              "      <td>43.1127</td>\n",
              "      <td>7.281591</td>\n",
              "      <td>9.331540</td>\n",
              "      <td>0.101580</td>\n",
              "      <td>1.331023</td>\n",
              "      <td>6.77040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>3.1468</td>\n",
              "      <td>8.0851</td>\n",
              "      <td>...</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "      <td>1415.3636</td>\n",
              "      <td>-47.3797</td>\n",
              "      <td>40.5632</td>\n",
              "      <td>7.076818</td>\n",
              "      <td>10.336130</td>\n",
              "      <td>-0.351734</td>\n",
              "      <td>4.110215</td>\n",
              "      <td>7.22315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>-4.9193</td>\n",
              "      <td>5.9525</td>\n",
              "      <td>...</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "      <td>1240.8966</td>\n",
              "      <td>-22.4038</td>\n",
              "      <td>33.8820</td>\n",
              "      <td>6.204483</td>\n",
              "      <td>8.753387</td>\n",
              "      <td>-0.056957</td>\n",
              "      <td>0.546438</td>\n",
              "      <td>5.89940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>-5.8609</td>\n",
              "      <td>8.2450</td>\n",
              "      <td>...</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "      <td>1288.2319</td>\n",
              "      <td>-35.1659</td>\n",
              "      <td>38.1015</td>\n",
              "      <td>6.441159</td>\n",
              "      <td>9.594064</td>\n",
              "      <td>-0.480116</td>\n",
              "      <td>2.630499</td>\n",
              "      <td>6.70260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>7.6784</td>\n",
              "      <td>...</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "      <td>1354.2310</td>\n",
              "      <td>-65.4863</td>\n",
              "      <td>41.1037</td>\n",
              "      <td>6.771155</td>\n",
              "      <td>11.287122</td>\n",
              "      <td>-1.463426</td>\n",
              "      <td>9.787399</td>\n",
              "      <td>6.94735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 208 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
              "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
              "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
              "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
              "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
              "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
              "\n",
              "    var_9   ...     var_198  var_199        sum      min      max      mean  \\\n",
              "0  5.7470   ...     12.7803  -1.0914  1456.3182 -21.4494  43.1127  7.281591   \n",
              "1  8.0851   ...     18.3560   1.9518  1415.3636 -47.3797  40.5632  7.076818   \n",
              "2  5.9525   ...     14.7222   0.3965  1240.8966 -22.4038  33.8820  6.204483   \n",
              "3  8.2450   ...     17.9697  -8.9996  1288.2319 -35.1659  38.1015  6.441159   \n",
              "4  7.6784   ...     17.9974  -8.8104  1354.2310 -65.4863  41.1037  6.771155   \n",
              "\n",
              "         std      skew      kurt      med  \n",
              "0   9.331540  0.101580  1.331023  6.77040  \n",
              "1  10.336130 -0.351734  4.110215  7.22315  \n",
              "2   8.753387 -0.056957  0.546438  5.89940  \n",
              "3   9.594064 -0.480116  2.630499  6.70260  \n",
              "4  11.287122 -1.463426  9.787399  6.94735  \n",
              "\n",
              "[5 rows x 208 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "pe5Ntxndcrnb",
        "colab_type": "code",
        "outputId": "1acef777-d88e-4a84-ca32-40a8b8beb1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "X_test = merged.iloc[len_train:]\n",
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "      <th>sum</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurt</th>\n",
              "      <th>med</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0656</td>\n",
              "      <td>7.7798</td>\n",
              "      <td>12.9536</td>\n",
              "      <td>9.4292</td>\n",
              "      <td>11.4327</td>\n",
              "      <td>-2.3805</td>\n",
              "      <td>5.8493</td>\n",
              "      <td>18.2675</td>\n",
              "      <td>2.1337</td>\n",
              "      <td>8.8100</td>\n",
              "      <td>...</td>\n",
              "      <td>15.4722</td>\n",
              "      <td>-8.7197</td>\n",
              "      <td>1416.6404</td>\n",
              "      <td>-31.9891</td>\n",
              "      <td>42.0248</td>\n",
              "      <td>7.083202</td>\n",
              "      <td>9.910632</td>\n",
              "      <td>-0.088518</td>\n",
              "      <td>1.871262</td>\n",
              "      <td>7.31440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.5304</td>\n",
              "      <td>1.2543</td>\n",
              "      <td>11.3047</td>\n",
              "      <td>5.1858</td>\n",
              "      <td>9.1974</td>\n",
              "      <td>-4.0117</td>\n",
              "      <td>6.0196</td>\n",
              "      <td>18.6316</td>\n",
              "      <td>-4.4131</td>\n",
              "      <td>5.9739</td>\n",
              "      <td>...</td>\n",
              "      <td>19.1293</td>\n",
              "      <td>-20.9760</td>\n",
              "      <td>1249.6860</td>\n",
              "      <td>-41.1924</td>\n",
              "      <td>35.6020</td>\n",
              "      <td>6.248430</td>\n",
              "      <td>9.541267</td>\n",
              "      <td>-0.559785</td>\n",
              "      <td>3.391068</td>\n",
              "      <td>6.43960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.4827</td>\n",
              "      <td>-10.3581</td>\n",
              "      <td>10.1407</td>\n",
              "      <td>7.0479</td>\n",
              "      <td>10.2628</td>\n",
              "      <td>9.8052</td>\n",
              "      <td>4.8950</td>\n",
              "      <td>20.2537</td>\n",
              "      <td>1.5233</td>\n",
              "      <td>8.3442</td>\n",
              "      <td>...</td>\n",
              "      <td>19.8956</td>\n",
              "      <td>-23.1794</td>\n",
              "      <td>1430.2599</td>\n",
              "      <td>-34.3488</td>\n",
              "      <td>39.3654</td>\n",
              "      <td>7.151299</td>\n",
              "      <td>9.967466</td>\n",
              "      <td>-0.135084</td>\n",
              "      <td>2.326901</td>\n",
              "      <td>7.26355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5374</td>\n",
              "      <td>-1.3222</td>\n",
              "      <td>12.0220</td>\n",
              "      <td>6.5749</td>\n",
              "      <td>8.8458</td>\n",
              "      <td>3.1744</td>\n",
              "      <td>4.9397</td>\n",
              "      <td>20.5660</td>\n",
              "      <td>3.3755</td>\n",
              "      <td>7.4578</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0168</td>\n",
              "      <td>-4.2108</td>\n",
              "      <td>1411.4447</td>\n",
              "      <td>-21.4797</td>\n",
              "      <td>40.3383</td>\n",
              "      <td>7.057223</td>\n",
              "      <td>8.257204</td>\n",
              "      <td>-0.167741</td>\n",
              "      <td>2.253054</td>\n",
              "      <td>6.89675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.7058</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>14.1295</td>\n",
              "      <td>7.7506</td>\n",
              "      <td>9.1035</td>\n",
              "      <td>-8.5848</td>\n",
              "      <td>6.8595</td>\n",
              "      <td>10.6048</td>\n",
              "      <td>2.9890</td>\n",
              "      <td>7.1437</td>\n",
              "      <td>...</td>\n",
              "      <td>13.9260</td>\n",
              "      <td>-9.1846</td>\n",
              "      <td>1423.7364</td>\n",
              "      <td>-24.8254</td>\n",
              "      <td>45.5510</td>\n",
              "      <td>7.118682</td>\n",
              "      <td>10.043542</td>\n",
              "      <td>0.293484</td>\n",
              "      <td>2.044943</td>\n",
              "      <td>6.83375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 208 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
              "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
              "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
              "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
              "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
              "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
              "\n",
              "    var_8   var_9   ...     var_198  var_199        sum      min      max  \\\n",
              "0  2.1337  8.8100   ...     15.4722  -8.7197  1416.6404 -31.9891  42.0248   \n",
              "1 -4.4131  5.9739   ...     19.1293 -20.9760  1249.6860 -41.1924  35.6020   \n",
              "2  1.5233  8.3442   ...     19.8956 -23.1794  1430.2599 -34.3488  39.3654   \n",
              "3  3.3755  7.4578   ...     13.0168  -4.2108  1411.4447 -21.4797  40.3383   \n",
              "4  2.9890  7.1437   ...     13.9260  -9.1846  1423.7364 -24.8254  45.5510   \n",
              "\n",
              "       mean        std      skew      kurt      med  \n",
              "0  7.083202   9.910632 -0.088518  1.871262  7.31440  \n",
              "1  6.248430   9.541267 -0.559785  3.391068  6.43960  \n",
              "2  7.151299   9.967466 -0.135084  2.326901  7.26355  \n",
              "3  7.057223   8.257204 -0.167741  2.253054  6.89675  \n",
              "4  7.118682  10.043542  0.293484  2.044943  6.83375  \n",
              "\n",
              "[5 rows x 208 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "9smQ33tKcyvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data Augment Augmentation is a method to increase the amount of training data by randomly shuffle/transform the features in a certain way. It improves accuracy by letting the model see more cases of both \"1\" and \"0\" samples in training so the model can generalize better to new data.\n",
        "\n",
        "Thanks to Jiwei Lu for teaching this new concept . https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment"
      ]
    },
    {
      "metadata": {
        "id": "XjppBYM2cuTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment(x,y,t=2):\n",
        "    xs,xn = [],[]\n",
        "    for i in range(t):\n",
        "        mask = y>0\n",
        "        x1 = x[mask].copy()\n",
        "        ids = np.arange(x1.shape[0])\n",
        "        for c in range(x1.shape[1]):\n",
        "            np.random.shuffle(ids)\n",
        "            x1[:,c] = x1[ids][:,c]\n",
        "        xs.append(x1)\n",
        "\n",
        "    for i in range(t//2):\n",
        "        mask = y==0\n",
        "        x1 = x[mask].copy()\n",
        "        ids = np.arange(x1.shape[0])\n",
        "        for c in range(x1.shape[1]):\n",
        "            np.random.shuffle(ids)\n",
        "            x1[:,c] = x1[ids][:,c]\n",
        "        xn.append(x1)\n",
        "\n",
        "    xs = np.vstack(xs)\n",
        "    xn = np.vstack(xn)\n",
        "    ys = np.ones(xs.shape[0])\n",
        "    yn = np.zeros(xn.shape[0])\n",
        "    x = np.vstack([x,xs,xn])\n",
        "    y = np.concatenate([y,ys,yn])\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I34mLG_qc4vL",
        "colab_type": "code",
        "outputId": "b9c40f83-c7db-4a6b-bbe1-0ecaede687ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"train_df = santander_data\n",
        "X_test = santander_data_test\"\"\"\n",
        "del santander_data\n",
        "del santander_data_test\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "4m8Zh0bWc63K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "skf_three= StratifiedKFold(n_splits=12, shuffle=False, random_state=2319)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21dBmPypc_Hp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param = {\n",
        "    \"objective\" : \"binary\",\n",
        "    \"metric\" : \"auc\",\n",
        "    \"boosting\": 'gbdt',\n",
        "    \"max_depth\" : -1,\n",
        "    \"num_leaves\" : 13,\n",
        "    \"learning_rate\" : 0.01,\n",
        "    \"bagging_freq\": 5,\n",
        "    \"bagging_fraction\" : 0.4,\n",
        "    \"feature_fraction\" : 0.05,\n",
        "    \"min_data_in_leaf\": 80,\n",
        "    \"min_sum_heassian_in_leaf\": 10,\n",
        "    \"tree_learner\": \"serial\",\n",
        "    \"boost_from_average\": \"false\",\n",
        "    #\"lambda_l1\" : 5,\n",
        "    #\"lambda_l2\" : 5,\n",
        "    \"verbosity\" : 1,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q48U3MP1dBRx",
        "colab_type": "code",
        "outputId": "08ef7cc5-fed8-4a08-ed7e-32c74518f82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2338
        }
      },
      "cell_type": "code",
      "source": [
        "# Create arrays and dataframes to store results\n",
        "oof_preds = np.zeros(train_df.shape[0])\n",
        "sub_preds = np.zeros(len(X_test))\n",
        "feats = [f for f in train_df.columns]\n",
        "    \n",
        "for n_fold, (train_idx, valid_idx) in enumerate(skf_three.split(train_df[feats], label_df)):\n",
        "    X_train, y_train = train_df.iloc[train_idx][feats], label_df.iloc[train_idx]\n",
        "    X_valid, y_valid = train_df.iloc[valid_idx][feats], label_df.iloc[valid_idx]\n",
        "    \n",
        "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
        "    X_tr = pd.DataFrame(X_tr)\n",
        "    \n",
        "    print(\"Fold idx:{}\".format(n_fold + 1))\n",
        "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
        "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
        "        \n",
        "    clf = lgb.train(param, trn_data,1000000, valid_sets = [trn_data, val_data], verbose_eval=2000, early_stopping_rounds = 4000)\n",
        "        \n",
        "\n",
        "    oof_preds[valid_idx] = clf.predict(train_df.iloc[valid_idx][feats], num_iteration=clf.best_iteration)\n",
        "    sub_preds += clf.predict(X_test[feats], num_iteration=clf.best_iteration) / 12\n",
        "\n",
        "\n",
        "print('Full AUC score %.6f' % roc_auc_score(label_df, oof_preds))\n",
        "\n",
        "\n",
        "pred3=sub_preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold idx:1\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900718\tvalid_1's auc: 0.886382\n",
            "[4000]\ttraining's auc: 0.911551\tvalid_1's auc: 0.894677\n",
            "[6000]\ttraining's auc: 0.918087\tvalid_1's auc: 0.898908\n",
            "[8000]\ttraining's auc: 0.92275\tvalid_1's auc: 0.900457\n",
            "[10000]\ttraining's auc: 0.926807\tvalid_1's auc: 0.901593\n",
            "[12000]\ttraining's auc: 0.930668\tvalid_1's auc: 0.901954\n",
            "[14000]\ttraining's auc: 0.934356\tvalid_1's auc: 0.902061\n",
            "[16000]\ttraining's auc: 0.937883\tvalid_1's auc: 0.90199\n",
            "[18000]\ttraining's auc: 0.941275\tvalid_1's auc: 0.9018\n",
            "Early stopping, best iteration is:\n",
            "[14115]\ttraining's auc: 0.934556\tvalid_1's auc: 0.90211\n",
            "Fold idx:2\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901143\tvalid_1's auc: 0.888357\n",
            "[4000]\ttraining's auc: 0.911882\tvalid_1's auc: 0.894944\n",
            "[6000]\ttraining's auc: 0.918424\tvalid_1's auc: 0.897669\n",
            "[8000]\ttraining's auc: 0.923107\tvalid_1's auc: 0.898639\n",
            "[10000]\ttraining's auc: 0.927155\tvalid_1's auc: 0.899071\n",
            "[12000]\ttraining's auc: 0.931013\tvalid_1's auc: 0.899057\n",
            "[14000]\ttraining's auc: 0.934679\tvalid_1's auc: 0.899163\n",
            "[16000]\ttraining's auc: 0.938197\tvalid_1's auc: 0.899004\n",
            "[18000]\ttraining's auc: 0.941548\tvalid_1's auc: 0.898887\n",
            "Early stopping, best iteration is:\n",
            "[14599]\ttraining's auc: 0.935742\tvalid_1's auc: 0.899216\n",
            "Fold idx:3\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901395\tvalid_1's auc: 0.879263\n",
            "[4000]\ttraining's auc: 0.91242\tvalid_1's auc: 0.887152\n",
            "[6000]\ttraining's auc: 0.918942\tvalid_1's auc: 0.890385\n",
            "[8000]\ttraining's auc: 0.923649\tvalid_1's auc: 0.891715\n",
            "[10000]\ttraining's auc: 0.927686\tvalid_1's auc: 0.891961\n",
            "[12000]\ttraining's auc: 0.931464\tvalid_1's auc: 0.892015\n",
            "[14000]\ttraining's auc: 0.935075\tvalid_1's auc: 0.891884\n",
            "Early stopping, best iteration is:\n",
            "[10848]\ttraining's auc: 0.929318\tvalid_1's auc: 0.892048\n",
            "Fold idx:4\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900486\tvalid_1's auc: 0.892662\n",
            "[4000]\ttraining's auc: 0.911273\tvalid_1's auc: 0.901336\n",
            "[6000]\ttraining's auc: 0.917775\tvalid_1's auc: 0.904678\n",
            "[8000]\ttraining's auc: 0.922415\tvalid_1's auc: 0.90578\n",
            "[10000]\ttraining's auc: 0.926506\tvalid_1's auc: 0.906098\n",
            "[12000]\ttraining's auc: 0.930349\tvalid_1's auc: 0.906094\n",
            "[14000]\ttraining's auc: 0.93399\tvalid_1's auc: 0.906036\n",
            "Early stopping, best iteration is:\n",
            "[11072]\ttraining's auc: 0.92858\tvalid_1's auc: 0.906275\n",
            "Fold idx:5\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901684\tvalid_1's auc: 0.881254\n",
            "[4000]\ttraining's auc: 0.912541\tvalid_1's auc: 0.88901\n",
            "[6000]\ttraining's auc: 0.919041\tvalid_1's auc: 0.89218\n",
            "[8000]\ttraining's auc: 0.923704\tvalid_1's auc: 0.893297\n",
            "[10000]\ttraining's auc: 0.927783\tvalid_1's auc: 0.893714\n",
            "[12000]\ttraining's auc: 0.931586\tvalid_1's auc: 0.893832\n",
            "[14000]\ttraining's auc: 0.935236\tvalid_1's auc: 0.893744\n",
            "Early stopping, best iteration is:\n",
            "[11401]\ttraining's auc: 0.930442\tvalid_1's auc: 0.893922\n",
            "Fold idx:6\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900843\tvalid_1's auc: 0.890115\n",
            "[4000]\ttraining's auc: 0.911881\tvalid_1's auc: 0.896456\n",
            "[6000]\ttraining's auc: 0.918471\tvalid_1's auc: 0.898741\n",
            "[8000]\ttraining's auc: 0.923185\tvalid_1's auc: 0.899456\n",
            "[10000]\ttraining's auc: 0.927279\tvalid_1's auc: 0.899578\n",
            "[12000]\ttraining's auc: 0.931114\tvalid_1's auc: 0.899295\n",
            "[14000]\ttraining's auc: 0.934778\tvalid_1's auc: 0.89905\n",
            "Early stopping, best iteration is:\n",
            "[10472]\ttraining's auc: 0.928194\tvalid_1's auc: 0.899625\n",
            "Fold idx:7\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900673\tvalid_1's auc: 0.89103\n",
            "[4000]\ttraining's auc: 0.911543\tvalid_1's auc: 0.897807\n",
            "[6000]\ttraining's auc: 0.918053\tvalid_1's auc: 0.900462\n",
            "[8000]\ttraining's auc: 0.922758\tvalid_1's auc: 0.901313\n",
            "[10000]\ttraining's auc: 0.92684\tvalid_1's auc: 0.90148\n",
            "[12000]\ttraining's auc: 0.930629\tvalid_1's auc: 0.90148\n",
            "[14000]\ttraining's auc: 0.934298\tvalid_1's auc: 0.901419\n",
            "[16000]\ttraining's auc: 0.937758\tvalid_1's auc: 0.901473\n",
            "Early stopping, best iteration is:\n",
            "[13553]\ttraining's auc: 0.933478\tvalid_1's auc: 0.901621\n",
            "Fold idx:8\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900262\tvalid_1's auc: 0.894728\n",
            "[4000]\ttraining's auc: 0.911266\tvalid_1's auc: 0.901168\n",
            "[6000]\ttraining's auc: 0.917873\tvalid_1's auc: 0.903609\n",
            "[8000]\ttraining's auc: 0.922629\tvalid_1's auc: 0.904471\n",
            "[10000]\ttraining's auc: 0.926676\tvalid_1's auc: 0.904731\n",
            "[12000]\ttraining's auc: 0.930519\tvalid_1's auc: 0.904661\n",
            "Early stopping, best iteration is:\n",
            "[9792]\ttraining's auc: 0.92627\tvalid_1's auc: 0.904785\n",
            "Fold idx:9\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901185\tvalid_1's auc: 0.885775\n",
            "[4000]\ttraining's auc: 0.912056\tvalid_1's auc: 0.893708\n",
            "[6000]\ttraining's auc: 0.918663\tvalid_1's auc: 0.897087\n",
            "[8000]\ttraining's auc: 0.923337\tvalid_1's auc: 0.898185\n",
            "[10000]\ttraining's auc: 0.927392\tvalid_1's auc: 0.898594\n",
            "[12000]\ttraining's auc: 0.931225\tvalid_1's auc: 0.898631\n",
            "[14000]\ttraining's auc: 0.934849\tvalid_1's auc: 0.898673\n",
            "[16000]\ttraining's auc: 0.938336\tvalid_1's auc: 0.898768\n",
            "[18000]\ttraining's auc: 0.941692\tvalid_1's auc: 0.898767\n",
            "[20000]\ttraining's auc: 0.944994\tvalid_1's auc: 0.898461\n",
            "Early stopping, best iteration is:\n",
            "[16807]\ttraining's auc: 0.939731\tvalid_1's auc: 0.898828\n",
            "Fold idx:10\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901271\tvalid_1's auc: 0.891884\n",
            "[4000]\ttraining's auc: 0.912157\tvalid_1's auc: 0.899575\n",
            "[6000]\ttraining's auc: 0.918718\tvalid_1's auc: 0.902769\n",
            "[8000]\ttraining's auc: 0.923396\tvalid_1's auc: 0.903798\n",
            "[10000]\ttraining's auc: 0.927437\tvalid_1's auc: 0.904046\n",
            "[12000]\ttraining's auc: 0.931265\tvalid_1's auc: 0.90394\n",
            "[14000]\ttraining's auc: 0.934881\tvalid_1's auc: 0.903925\n",
            "Early stopping, best iteration is:\n",
            "[10211]\ttraining's auc: 0.927862\tvalid_1's auc: 0.904091\n",
            "Fold idx:11\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.900517\tvalid_1's auc: 0.895137\n",
            "[4000]\ttraining's auc: 0.911333\tvalid_1's auc: 0.903047\n",
            "[6000]\ttraining's auc: 0.917908\tvalid_1's auc: 0.90635\n",
            "[8000]\ttraining's auc: 0.922592\tvalid_1's auc: 0.907523\n",
            "[10000]\ttraining's auc: 0.926733\tvalid_1's auc: 0.907766\n",
            "[12000]\ttraining's auc: 0.930601\tvalid_1's auc: 0.907699\n",
            "[14000]\ttraining's auc: 0.934295\tvalid_1's auc: 0.907704\n",
            "Early stopping, best iteration is:\n",
            "[10504]\ttraining's auc: 0.927725\tvalid_1's auc: 0.907842\n",
            "Fold idx:12\n",
            "Training until validation scores don't improve for 4000 rounds.\n",
            "[2000]\ttraining's auc: 0.901594\tvalid_1's auc: 0.888847\n",
            "[4000]\ttraining's auc: 0.91251\tvalid_1's auc: 0.895697\n",
            "[6000]\ttraining's auc: 0.919016\tvalid_1's auc: 0.899088\n",
            "[8000]\ttraining's auc: 0.923662\tvalid_1's auc: 0.90019\n",
            "[10000]\ttraining's auc: 0.927727\tvalid_1's auc: 0.900275\n",
            "[12000]\ttraining's auc: 0.931521\tvalid_1's auc: 0.900451\n",
            "[14000]\ttraining's auc: 0.935068\tvalid_1's auc: 0.900469\n",
            "[16000]\ttraining's auc: 0.938527\tvalid_1's auc: 0.900297\n",
            "Early stopping, best iteration is:\n",
            "[12394]\ttraining's auc: 0.932218\tvalid_1's auc: 0.900529\n",
            "Full AUC score 0.900781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DO-qIcWPrlas",
        "colab_type": "code",
        "outputId": "7a35614e-7557-4d16-90e9-a047b2c8f4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv')\n",
        "sample_submission['target'] = pred3\n",
        "sample_submission.to_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/submission_last_run2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-39b2b4199026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/submission_last_run2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred3' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bO68z_cCCq09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mean_auc = np.mean(pred3)\n",
        "# std_auc = np.std(pred3)\n",
        "# all_auc = roc_auc_score(label_df, oof_preds)\n",
        "# print(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUH3aLLJYUa7",
        "colab_type": "code",
        "outputId": "98fdbc8d-1950-402b-e6c9-2f4082dd14b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv')\n",
        "sample_submission['target'] = pred3\n",
        "sample_submission.to_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/submission_last_run2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-39b2b4199026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/submission_last_run2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred3' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gL5kgR2TdFVx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sample_submission = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/sample_submission.csv')\n",
        "# sample_submission['target'] = pred3\n",
        "# sample_submission.to_csv('submission_best.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7s4TUHknxBP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_state = 42\n",
        "np.random.seed(random_state)\n",
        "df_train = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/train.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIeWXgyzn413",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def disarrange(a, axis=-1):\n",
        "    \"\"\"\n",
        "    Shuffle `a` in-place along the given axis.\n",
        "\n",
        "    Apply numpy.random.shuffle to the given axis of `a`.\n",
        "    Each one-dimensional slice is shuffled independently.\n",
        "    \"\"\"\n",
        "    b = a.swapaxes(axis, -1)\n",
        "    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n",
        "    # so `a` is shuffled in place, too.\n",
        "    shp = b.shape[:-1]\n",
        "    for ndx in np.ndindex(shp):\n",
        "        np.random.shuffle(b[ndx])\n",
        "    return\n",
        "\n",
        "\n",
        "def augment(x,y,t=2):\n",
        "    xs,xn = [],[]\n",
        "    for i in range(t):\n",
        "        mask = y>0\n",
        "        x1 = x[mask].copy()\n",
        "        disarrange(x1,axis=0)\n",
        "        xs.append(x1)\n",
        "\n",
        "    for i in range(t//2):\n",
        "        mask = y==0\n",
        "        x1 = x[mask].copy()\n",
        "        disarrange(x1,axis=0)\n",
        "        xn.append(x1)\n",
        "\n",
        "    xs = np.vstack(xs)\n",
        "    xn = np.vstack(xn)\n",
        "    ys = np.ones(xs.shape[0])\n",
        "    yn = np.zeros(xn.shape[0])\n",
        "    x = np.vstack([x,xs,xn])\n",
        "    y = np.concatenate([y,ys,yn])\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FevuKzG6n8IN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# lgb_params = {\n",
        "#     \"objective\" : \"binary\",\n",
        "#     \"metric\" : \"auc\",\n",
        "#     \"boosting\": 'gbdt',\n",
        "#     \"max_depth\" : -1,\n",
        "#     \"num_leaves\" : 13,\n",
        "#     \"learning_rate\" : 0.01,\n",
        "#     \"bagging_freq\": 5,\n",
        "#     \"bagging_fraction\" : 0.4,\n",
        "#     \"feature_fraction\" : 0.05,\n",
        "#     \"min_data_in_leaf\": 80,\n",
        "#     \"min_sum_heassian_in_leaf\": 10,\n",
        "#     \"tree_learner\": \"serial\",\n",
        "#     \"boost_from_average\": \"false\",\n",
        "#     #\"lambda_l1\" : 5,\n",
        "#     #\"lambda_l2\" : 5,\n",
        "#     \"bagging_seed\" : random_state,\n",
        "#     \"verbosity\" : 1,\n",
        "#     \"seed\": random_state\n",
        "# }\n",
        "\n",
        "lgb_params = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary',\n",
        "    \"bagging_seed\" : random_state,\n",
        "    'verbosity': -1,\n",
        "    \"seed\": random_state\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNRVu6rJn8ih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=11, shuffle=True, random_state=random_state)\n",
        "oof = df_train[['ID_code', 'target']]\n",
        "oof['predict'] = 0\n",
        "predictions = df_test[['ID_code']]\n",
        "val_aucs = []\n",
        "feature_importance_df = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kB-qJaZyoBh9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = [col for col in df_train.columns if col not in ['target', 'ID_code']]\n",
        "X_test = df_test[features].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWveE5tToDMr",
        "colab_type": "code",
        "outputId": "f7d3cf32-c837-4b71-bed2-2999fa447a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3672
        }
      },
      "cell_type": "code",
      "source": [
        "for fold, (trn_idx, val_idx) in enumerate(skf.split(df_train, df_train['target'])):\n",
        "    X_train, y_train = df_train.iloc[trn_idx][features], df_train.iloc[trn_idx]['target']\n",
        "    X_valid, y_valid = df_train.iloc[val_idx][features], df_train.iloc[val_idx]['target']\n",
        "    \n",
        "    N = 11\n",
        "    p_valid,yp = 0,0\n",
        "    for i in range(N):\n",
        "        X_t, y_t = augment(X_train.values, y_train.values)\n",
        "        X_t = pd.DataFrame(X_t)\n",
        "        X_t = X_t.add_prefix('var_')\n",
        "    \n",
        "        trn_data = lgb.Dataset(X_t, label=y_t)\n",
        "        val_data = lgb.Dataset(X_valid, label=y_valid)\n",
        "        evals_result = {}\n",
        "        lgb_clf = lgb.train(lgb_params,\n",
        "                        trn_data,\n",
        "                        100000,\n",
        "                        valid_sets = [trn_data, val_data],\n",
        "                        early_stopping_rounds=3000,\n",
        "                        verbose_eval = 1000,\n",
        "                        evals_result=evals_result\n",
        "                       )\n",
        "        p_valid += lgb_clf.predict(X_valid)\n",
        "        yp += lgb_clf.predict(X_test)\n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"feature\"] = features\n",
        "    fold_importance_df[\"importance\"] = lgb_clf.feature_importance()\n",
        "    fold_importance_df[\"fold\"] = fold + 1\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "    oof['predict'][val_idx] = p_valid/N\n",
        "    val_score = roc_auc_score(y_valid, p_valid)\n",
        "    val_aucs.append(val_score)\n",
        "    \n",
        "    predictions['fold{}'.format(fold+1)] = yp/N"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.89528\tvalid_1's auc: 0.887129\n",
            "[2000]\ttraining's auc: 0.90138\tvalid_1's auc: 0.892304\n",
            "[3000]\ttraining's auc: 0.9057\tvalid_1's auc: 0.895246\n",
            "[4000]\ttraining's auc: 0.909167\tvalid_1's auc: 0.897104\n",
            "[5000]\ttraining's auc: 0.912047\tvalid_1's auc: 0.898671\n",
            "[6000]\ttraining's auc: 0.914508\tvalid_1's auc: 0.899839\n",
            "[7000]\ttraining's auc: 0.916685\tvalid_1's auc: 0.900542\n",
            "[8000]\ttraining's auc: 0.918625\tvalid_1's auc: 0.901196\n",
            "[9000]\ttraining's auc: 0.920385\tvalid_1's auc: 0.901609\n",
            "[10000]\ttraining's auc: 0.922063\tvalid_1's auc: 0.90198\n",
            "[11000]\ttraining's auc: 0.923656\tvalid_1's auc: 0.90215\n",
            "[12000]\ttraining's auc: 0.925187\tvalid_1's auc: 0.902288\n",
            "[13000]\ttraining's auc: 0.926676\tvalid_1's auc: 0.902315\n",
            "[14000]\ttraining's auc: 0.928131\tvalid_1's auc: 0.902294\n",
            "[15000]\ttraining's auc: 0.929545\tvalid_1's auc: 0.902455\n",
            "[16000]\ttraining's auc: 0.930934\tvalid_1's auc: 0.902472\n",
            "[17000]\ttraining's auc: 0.932318\tvalid_1's auc: 0.902444\n",
            "[18000]\ttraining's auc: 0.933687\tvalid_1's auc: 0.902448\n",
            "[19000]\ttraining's auc: 0.935057\tvalid_1's auc: 0.902408\n",
            "Early stopping, best iteration is:\n",
            "[16264]\ttraining's auc: 0.931309\tvalid_1's auc: 0.902532\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.894601\tvalid_1's auc: 0.887548\n",
            "[2000]\ttraining's auc: 0.900656\tvalid_1's auc: 0.892682\n",
            "[3000]\ttraining's auc: 0.905028\tvalid_1's auc: 0.895567\n",
            "[4000]\ttraining's auc: 0.908468\tvalid_1's auc: 0.89776\n",
            "[5000]\ttraining's auc: 0.911337\tvalid_1's auc: 0.899476\n",
            "[6000]\ttraining's auc: 0.913815\tvalid_1's auc: 0.900558\n",
            "[7000]\ttraining's auc: 0.915978\tvalid_1's auc: 0.901516\n",
            "[8000]\ttraining's auc: 0.917914\tvalid_1's auc: 0.901996\n",
            "[9000]\ttraining's auc: 0.919677\tvalid_1's auc: 0.902292\n",
            "[10000]\ttraining's auc: 0.921362\tvalid_1's auc: 0.902657\n",
            "[11000]\ttraining's auc: 0.922962\tvalid_1's auc: 0.902849\n",
            "[12000]\ttraining's auc: 0.924512\tvalid_1's auc: 0.902958\n",
            "[13000]\ttraining's auc: 0.926002\tvalid_1's auc: 0.902973\n",
            "[14000]\ttraining's auc: 0.927468\tvalid_1's auc: 0.902925\n",
            "[15000]\ttraining's auc: 0.928897\tvalid_1's auc: 0.902957\n",
            "Early stopping, best iteration is:\n",
            "[12576]\ttraining's auc: 0.925359\tvalid_1's auc: 0.903018\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.894549\tvalid_1's auc: 0.888108\n",
            "[2000]\ttraining's auc: 0.900463\tvalid_1's auc: 0.892944\n",
            "[3000]\ttraining's auc: 0.904843\tvalid_1's auc: 0.895887\n",
            "[4000]\ttraining's auc: 0.908298\tvalid_1's auc: 0.897981\n",
            "[5000]\ttraining's auc: 0.91118\tvalid_1's auc: 0.899474\n",
            "[6000]\ttraining's auc: 0.913688\tvalid_1's auc: 0.900515\n",
            "[7000]\ttraining's auc: 0.915901\tvalid_1's auc: 0.901607\n",
            "[8000]\ttraining's auc: 0.917815\tvalid_1's auc: 0.902209\n",
            "[9000]\ttraining's auc: 0.91961\tvalid_1's auc: 0.902525\n",
            "[10000]\ttraining's auc: 0.9213\tvalid_1's auc: 0.902822\n",
            "[11000]\ttraining's auc: 0.922912\tvalid_1's auc: 0.90302\n",
            "[12000]\ttraining's auc: 0.924476\tvalid_1's auc: 0.903104\n",
            "[13000]\ttraining's auc: 0.925986\tvalid_1's auc: 0.903302\n",
            "[14000]\ttraining's auc: 0.927475\tvalid_1's auc: 0.903324\n",
            "[15000]\ttraining's auc: 0.928921\tvalid_1's auc: 0.903246\n",
            "[16000]\ttraining's auc: 0.930351\tvalid_1's auc: 0.903194\n",
            "[17000]\ttraining's auc: 0.931762\tvalid_1's auc: 0.903135\n",
            "Early stopping, best iteration is:\n",
            "[14085]\ttraining's auc: 0.927597\tvalid_1's auc: 0.903347\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.894429\tvalid_1's auc: 0.887182\n",
            "[2000]\ttraining's auc: 0.900622\tvalid_1's auc: 0.89219\n",
            "[3000]\ttraining's auc: 0.904889\tvalid_1's auc: 0.895364\n",
            "[4000]\ttraining's auc: 0.908357\tvalid_1's auc: 0.897682\n",
            "[5000]\ttraining's auc: 0.911214\tvalid_1's auc: 0.899197\n",
            "[6000]\ttraining's auc: 0.913682\tvalid_1's auc: 0.900013\n",
            "[7000]\ttraining's auc: 0.915845\tvalid_1's auc: 0.901008\n",
            "[8000]\ttraining's auc: 0.917745\tvalid_1's auc: 0.901565\n",
            "[9000]\ttraining's auc: 0.919506\tvalid_1's auc: 0.90187\n",
            "[10000]\ttraining's auc: 0.921209\tvalid_1's auc: 0.902095\n",
            "[11000]\ttraining's auc: 0.922829\tvalid_1's auc: 0.902302\n",
            "[12000]\ttraining's auc: 0.924363\tvalid_1's auc: 0.902507\n",
            "[13000]\ttraining's auc: 0.925869\tvalid_1's auc: 0.902569\n",
            "[14000]\ttraining's auc: 0.927359\tvalid_1's auc: 0.902546\n",
            "[15000]\ttraining's auc: 0.928804\tvalid_1's auc: 0.902568\n",
            "[16000]\ttraining's auc: 0.930221\tvalid_1's auc: 0.902584\n",
            "[17000]\ttraining's auc: 0.931629\tvalid_1's auc: 0.902507\n",
            "[18000]\ttraining's auc: 0.933023\tvalid_1's auc: 0.902445\n",
            "Early stopping, best iteration is:\n",
            "[15399]\ttraining's auc: 0.929382\tvalid_1's auc: 0.902656\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.894726\tvalid_1's auc: 0.88756\n",
            "[2000]\ttraining's auc: 0.900804\tvalid_1's auc: 0.892506\n",
            "[3000]\ttraining's auc: 0.905225\tvalid_1's auc: 0.895551\n",
            "[4000]\ttraining's auc: 0.908734\tvalid_1's auc: 0.897805\n",
            "[5000]\ttraining's auc: 0.911631\tvalid_1's auc: 0.899277\n",
            "[6000]\ttraining's auc: 0.914159\tvalid_1's auc: 0.900535\n",
            "[7000]\ttraining's auc: 0.916333\tvalid_1's auc: 0.90137\n",
            "[8000]\ttraining's auc: 0.918239\tvalid_1's auc: 0.901807\n",
            "[9000]\ttraining's auc: 0.91999\tvalid_1's auc: 0.902177\n",
            "[10000]\ttraining's auc: 0.921664\tvalid_1's auc: 0.902344\n",
            "[11000]\ttraining's auc: 0.923268\tvalid_1's auc: 0.902412\n",
            "[12000]\ttraining's auc: 0.924835\tvalid_1's auc: 0.902533\n",
            "[13000]\ttraining's auc: 0.926344\tvalid_1's auc: 0.902405\n",
            "[14000]\ttraining's auc: 0.927844\tvalid_1's auc: 0.902419\n",
            "Early stopping, best iteration is:\n",
            "[11770]\ttraining's auc: 0.924481\tvalid_1's auc: 0.902571\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.89512\tvalid_1's auc: 0.887424\n",
            "[2000]\ttraining's auc: 0.901401\tvalid_1's auc: 0.892528\n",
            "[3000]\ttraining's auc: 0.90571\tvalid_1's auc: 0.895588\n",
            "[4000]\ttraining's auc: 0.90914\tvalid_1's auc: 0.897562\n",
            "[5000]\ttraining's auc: 0.911961\tvalid_1's auc: 0.899113\n",
            "[6000]\ttraining's auc: 0.914417\tvalid_1's auc: 0.900248\n",
            "[7000]\ttraining's auc: 0.916594\tvalid_1's auc: 0.901041\n",
            "[8000]\ttraining's auc: 0.91851\tvalid_1's auc: 0.90148\n",
            "[9000]\ttraining's auc: 0.920284\tvalid_1's auc: 0.901803\n",
            "[10000]\ttraining's auc: 0.921933\tvalid_1's auc: 0.902032\n",
            "[11000]\ttraining's auc: 0.923527\tvalid_1's auc: 0.902238\n",
            "[12000]\ttraining's auc: 0.925051\tvalid_1's auc: 0.902335\n",
            "[13000]\ttraining's auc: 0.926538\tvalid_1's auc: 0.902438\n",
            "[14000]\ttraining's auc: 0.928\tvalid_1's auc: 0.902455\n",
            "[15000]\ttraining's auc: 0.929457\tvalid_1's auc: 0.902489\n",
            "[16000]\ttraining's auc: 0.930869\tvalid_1's auc: 0.902464\n",
            "[17000]\ttraining's auc: 0.932248\tvalid_1's auc: 0.902563\n",
            "[18000]\ttraining's auc: 0.933629\tvalid_1's auc: 0.902586\n",
            "[19000]\ttraining's auc: 0.934994\tvalid_1's auc: 0.902536\n",
            "[20000]\ttraining's auc: 0.936316\tvalid_1's auc: 0.902444\n",
            "[21000]\ttraining's auc: 0.937623\tvalid_1's auc: 0.902431\n",
            "Early stopping, best iteration is:\n",
            "[18495]\ttraining's auc: 0.934303\tvalid_1's auc: 0.902617\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.895114\tvalid_1's auc: 0.88794\n",
            "[2000]\ttraining's auc: 0.901283\tvalid_1's auc: 0.89253\n",
            "[3000]\ttraining's auc: 0.905607\tvalid_1's auc: 0.895594\n",
            "[4000]\ttraining's auc: 0.90904\tvalid_1's auc: 0.897777\n",
            "[5000]\ttraining's auc: 0.911864\tvalid_1's auc: 0.899247\n",
            "[6000]\ttraining's auc: 0.914354\tvalid_1's auc: 0.900217\n",
            "[7000]\ttraining's auc: 0.916545\tvalid_1's auc: 0.901149\n",
            "[8000]\ttraining's auc: 0.918476\tvalid_1's auc: 0.901681\n",
            "[9000]\ttraining's auc: 0.920272\tvalid_1's auc: 0.901931\n",
            "[10000]\ttraining's auc: 0.921944\tvalid_1's auc: 0.902171\n",
            "[11000]\ttraining's auc: 0.923544\tvalid_1's auc: 0.902312\n",
            "[12000]\ttraining's auc: 0.925089\tvalid_1's auc: 0.902458\n",
            "[13000]\ttraining's auc: 0.926609\tvalid_1's auc: 0.902671\n",
            "[14000]\ttraining's auc: 0.928073\tvalid_1's auc: 0.90263\n",
            "[15000]\ttraining's auc: 0.929518\tvalid_1's auc: 0.902714\n",
            "[16000]\ttraining's auc: 0.930928\tvalid_1's auc: 0.902701\n",
            "[17000]\ttraining's auc: 0.932327\tvalid_1's auc: 0.902697\n",
            "Early stopping, best iteration is:\n",
            "[14890]\ttraining's auc: 0.929362\tvalid_1's auc: 0.90275\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.895113\tvalid_1's auc: 0.887619\n",
            "[2000]\ttraining's auc: 0.901217\tvalid_1's auc: 0.892097\n",
            "[3000]\ttraining's auc: 0.905615\tvalid_1's auc: 0.895235\n",
            "[4000]\ttraining's auc: 0.90899\tvalid_1's auc: 0.897379\n",
            "[5000]\ttraining's auc: 0.911834\tvalid_1's auc: 0.899\n",
            "[6000]\ttraining's auc: 0.914299\tvalid_1's auc: 0.900002\n",
            "[7000]\ttraining's auc: 0.916466\tvalid_1's auc: 0.900866\n",
            "[8000]\ttraining's auc: 0.918351\tvalid_1's auc: 0.901383\n",
            "[9000]\ttraining's auc: 0.920121\tvalid_1's auc: 0.901818\n",
            "[10000]\ttraining's auc: 0.921796\tvalid_1's auc: 0.902035\n",
            "[11000]\ttraining's auc: 0.923422\tvalid_1's auc: 0.902228\n",
            "[12000]\ttraining's auc: 0.924985\tvalid_1's auc: 0.902443\n",
            "[13000]\ttraining's auc: 0.926513\tvalid_1's auc: 0.902473\n",
            "[14000]\ttraining's auc: 0.92798\tvalid_1's auc: 0.90251\n",
            "[15000]\ttraining's auc: 0.92942\tvalid_1's auc: 0.90238\n",
            "[16000]\ttraining's auc: 0.930835\tvalid_1's auc: 0.902326\n",
            "Early stopping, best iteration is:\n",
            "[13888]\ttraining's auc: 0.927818\tvalid_1's auc: 0.902544\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.895243\tvalid_1's auc: 0.888076\n",
            "[2000]\ttraining's auc: 0.901357\tvalid_1's auc: 0.89282\n",
            "[3000]\ttraining's auc: 0.905667\tvalid_1's auc: 0.895829\n",
            "[4000]\ttraining's auc: 0.909059\tvalid_1's auc: 0.897861\n",
            "[5000]\ttraining's auc: 0.911883\tvalid_1's auc: 0.899538\n",
            "[6000]\ttraining's auc: 0.914348\tvalid_1's auc: 0.900806\n",
            "[7000]\ttraining's auc: 0.91645\tvalid_1's auc: 0.901712\n",
            "[8000]\ttraining's auc: 0.918366\tvalid_1's auc: 0.90233\n",
            "[9000]\ttraining's auc: 0.920104\tvalid_1's auc: 0.902597\n",
            "[10000]\ttraining's auc: 0.921742\tvalid_1's auc: 0.902836\n",
            "[11000]\ttraining's auc: 0.923365\tvalid_1's auc: 0.903084\n",
            "[12000]\ttraining's auc: 0.924909\tvalid_1's auc: 0.903083\n",
            "[13000]\ttraining's auc: 0.926409\tvalid_1's auc: 0.903184\n",
            "[14000]\ttraining's auc: 0.927895\tvalid_1's auc: 0.903204\n",
            "[15000]\ttraining's auc: 0.92933\tvalid_1's auc: 0.903121\n",
            "[16000]\ttraining's auc: 0.930747\tvalid_1's auc: 0.903034\n",
            "[17000]\ttraining's auc: 0.932162\tvalid_1's auc: 0.902981\n",
            "Early stopping, best iteration is:\n",
            "[14443]\ttraining's auc: 0.928536\tvalid_1's auc: 0.903249\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.894991\tvalid_1's auc: 0.887427\n",
            "[2000]\ttraining's auc: 0.901092\tvalid_1's auc: 0.892589\n",
            "[3000]\ttraining's auc: 0.905444\tvalid_1's auc: 0.89548\n",
            "[4000]\ttraining's auc: 0.908925\tvalid_1's auc: 0.897554\n",
            "[5000]\ttraining's auc: 0.91178\tvalid_1's auc: 0.899234\n",
            "[6000]\ttraining's auc: 0.914256\tvalid_1's auc: 0.900378\n",
            "[7000]\ttraining's auc: 0.916419\tvalid_1's auc: 0.901172\n",
            "[8000]\ttraining's auc: 0.918337\tvalid_1's auc: 0.901791\n",
            "[9000]\ttraining's auc: 0.920113\tvalid_1's auc: 0.902014\n",
            "[10000]\ttraining's auc: 0.921821\tvalid_1's auc: 0.902247\n",
            "[11000]\ttraining's auc: 0.923454\tvalid_1's auc: 0.90244\n",
            "[12000]\ttraining's auc: 0.925032\tvalid_1's auc: 0.902534\n",
            "[13000]\ttraining's auc: 0.926535\tvalid_1's auc: 0.902589\n",
            "[14000]\ttraining's auc: 0.928018\tvalid_1's auc: 0.902689\n",
            "[15000]\ttraining's auc: 0.929461\tvalid_1's auc: 0.902786\n",
            "[16000]\ttraining's auc: 0.930889\tvalid_1's auc: 0.902767\n",
            "[17000]\ttraining's auc: 0.932289\tvalid_1's auc: 0.902817\n",
            "[18000]\ttraining's auc: 0.933676\tvalid_1's auc: 0.902789\n",
            "[19000]\ttraining's auc: 0.935036\tvalid_1's auc: 0.902683\n",
            "Early stopping, best iteration is:\n",
            "[16578]\ttraining's auc: 0.9317\tvalid_1's auc: 0.902863\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[1000]\ttraining's auc: 0.895199\tvalid_1's auc: 0.888146\n",
            "[2000]\ttraining's auc: 0.901191\tvalid_1's auc: 0.892844\n",
            "[3000]\ttraining's auc: 0.905487\tvalid_1's auc: 0.89591\n",
            "[4000]\ttraining's auc: 0.908962\tvalid_1's auc: 0.89783\n",
            "[5000]\ttraining's auc: 0.911794\tvalid_1's auc: 0.899337\n",
            "[6000]\ttraining's auc: 0.914264\tvalid_1's auc: 0.900476\n",
            "[7000]\ttraining's auc: 0.916442\tvalid_1's auc: 0.901326\n",
            "[8000]\ttraining's auc: 0.918356\tvalid_1's auc: 0.901785\n",
            "[9000]\ttraining's auc: 0.920095\tvalid_1's auc: 0.902127\n",
            "[10000]\ttraining's auc: 0.921729\tvalid_1's auc: 0.902456\n",
            "[11000]\ttraining's auc: 0.92333\tvalid_1's auc: 0.902664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SikJSdh5oGO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_auc = np.mean(val_aucs)\n",
        "std_auc = np.std(val_aucs)\n",
        "all_auc = roc_auc_score(oof['target'], oof['predict'])\n",
        "print(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ji7s3wN6oJ7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
        "        .groupby(\"feature\")\n",
        "        .mean()\n",
        "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
        "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
        "\n",
        "plt.figure(figsize=(14,26))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
        "plt.title('LightGBM Features (averaged over folds)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('lgbm_importances.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvZWUwlKoML7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# submission\n",
        "predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n",
        "predictions.to_csv('lgb_all_predictions.csv', index=None)\n",
        "sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n",
        "sub_df[\"target\"] = predictions['target']\n",
        "sub_df.to_csv(\"/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/lgb_submission.csv\", index=False)\n",
        "oof.to_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/lgb_oof.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AS_ROGgDoZWE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# submission\n",
        "predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n",
        "predictions.to_csv('lgb_all_predictions.csv', index=None)\n",
        "sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n",
        "sub_df[\"target\"] = predictions['target']\n",
        "sub_df.to_csv(\"/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/lgb_submission2.csv\", index=False)\n",
        "oof.to_csv('/content/drive/My Drive/kaggle/santander-customer-transaction-prediction/lgb_oof2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9cb18Ys7X3g4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}